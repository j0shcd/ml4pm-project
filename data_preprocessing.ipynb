{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pyarrow.parquet as pq\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# hv.renderer('bokeh').theme = 'dark_minimal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_root = Path(r\"C:\\Users\\Turquin\\Documents\\MLFPMA - Machine Learning for Predictive Maintenance Application\\Project\\Dataset\") # Raw string works without escaping \\\n",
    "dataset_root = Path(\"./Dataset\")\n",
    "\n",
    "@dataclass\n",
    "class Case():\n",
    "    info: pd.DataFrame\n",
    "    measurements: pd.DataFrame\n",
    "\n",
    "\n",
    "class RawDataset():\n",
    "    def __init__(self, root, unit = \"VG4\", load_training=False, load_synthetic=False, load_anomalies=False) -> None:\n",
    "        read_pq_file = lambda f: pq.read_table(root / f).to_pandas()\n",
    "        \n",
    "        cases = {\n",
    "            \"test\": [f\"{unit}_generator_data_testing_real_measurements.parquet\", root / f\"{unit}_generator_data_testing_real_info.csv\" ], \n",
    "        }\n",
    "\n",
    "        if load_training:\n",
    "            cases = {\n",
    "                **cases,\n",
    "                \"train\": [f\"{unit}_generator_data_training_measurements.parquet\", root / f\"{unit}_generator_data_training_info.csv\" ], \n",
    "            }\n",
    "\n",
    "        if load_synthetic:\n",
    "            cases = {\n",
    "                **cases,\n",
    "                \"test_s01\": [f\"{unit}_generator_data_testing_synthetic_01_measurements.parquet\", root / f\"{unit}_generator_data_testing_synthetic_01_info.csv\"], \n",
    "                \"test_s02\": [f\"{unit}_generator_data_testing_synthetic_02_measurements.parquet\", root / f\"{unit}_generator_data_testing_synthetic_02_info.csv\"]\n",
    "            }\n",
    "\n",
    "        if load_anomalies:\n",
    "            anomaly_folder = Path(\"synthetic_anomalies\")  # Relative path\n",
    "            subdataset = [\"01\", \"02\"]\n",
    "            anomaly_types = [\"a\", \"b\", \"c\"]\n",
    "            for anomaly in subdataset:\n",
    "                for subtype in anomaly_types:\n",
    "                    anomaly_key = f\"anomaly_{anomaly}_type_{subtype}\"\n",
    "                    anomaly_file = f\"{unit}_anomaly_{anomaly}_type_{subtype}.parquet\"\n",
    "                    full_anomaly_path = root / anomaly_folder / anomaly_file\n",
    "                    if full_anomaly_path.exists():\n",
    "                        cases[anomaly_key] = [anomaly_folder / anomaly_file, None]\n",
    "\n",
    "        \n",
    "        self.data_dict = dict()\n",
    "        \n",
    "        for id_c, c in cases.items():\n",
    "            # if you need to verify the parquet header:\n",
    "            # pq_rows = RawDataset.read_parquet_schema_df(root / c[0])\n",
    "            measurements = read_pq_file(c[0])\n",
    "            info = pd.read_csv(c[1]) if c[1] is not None else None\n",
    "            self.data_dict[id_c] = Case(info, measurements)\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_parquet_schema_df(uri: str) -> pd.DataFrame:\n",
    "        \"\"\"Return a Pandas dataframe corresponding to the schema of a local URI of a parquet file.\n",
    "\n",
    "        The returned dataframe has the columns: column, pa_dtype\n",
    "        \"\"\"\n",
    "        # Ref: https://stackoverflow.com/a/64288036/\n",
    "        schema = pq.read_schema(uri, memory_map=True)\n",
    "        schema = pd.DataFrame(({\"column\": name, \"pa_dtype\": str(pa_dtype)} for name, pa_dtype in zip(schema.names, schema.types)))\n",
    "        schema = schema.reindex(columns=[\"column\", \"pa_dtype\"], fill_value=pd.NA)  # Ensures columns in case the parquet file has an empty dataframe.\n",
    "        return schema\n",
    "    \n",
    "\n",
    "rds_u4 = RawDataset(dataset_root, \"VG4\", load_synthetic=False, load_training=True)\n",
    "rds_u5 = RawDataset(dataset_root, \"VG5\", load_synthetic=True, load_training=True, load_anomalies=True)\n",
    "rds_u6 = RawDataset(dataset_root, \"VG6\", load_synthetic=True, load_training=True, load_anomalies=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_anomaly_ground_truth(rds):\n",
    "    subdataset = [\"01\", \"02\"]\n",
    "    anomaly_types = [\"a\", \"b\", \"c\"]\n",
    "\n",
    "    results = []\n",
    "    for anomaly in subdataset:\n",
    "        test_s012 = rds.data_dict[f'test_s{anomaly}'].measurements\n",
    "\n",
    "        for subtype in anomaly_types:\n",
    "            anomaly_key = f\"anomaly_{anomaly}_type_{subtype}\"\n",
    "            labeled_df = rds.data_dict[anomaly_key].measurements\n",
    "            test_s012.loc[labeled_df['ground_truth'] == 1, anomaly_key] = 1\n",
    "        \n",
    "        test_s012['anomaly'] = (test_s012[[f'anomaly_{anomaly}_type_a',f'anomaly_{anomaly}_type_b',f'anomaly_{anomaly}_type_c']].max(axis=1) == 1).astype(int)\n",
    "        results.append(test_s012)\n",
    "\n",
    "    return results\n",
    "\n",
    "u5_s01, u5_s02 = add_anomaly_ground_truth(rds_u5)\n",
    "u6_s01, u6_s02 = add_anomaly_ground_truth(rds_u6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tot_activepower', 'charge', 'coupler_position',\n",
       "       'injector_01_opening', 'injector_02_opening',\n",
       "       'injector_03_opening', 'injector_04_opening',\n",
       "       'injector_05_opening', 'pump_calculated_flow',\n",
       "       'pump_pressure_diff', 'pump_rotspeed', 'turbine_pressure',\n",
       "       'turbine_rotspeed', 'water_primary_pump_01_opening',\n",
       "       'water_primary_pump_02_opening', 'timer_turbine_on_off',\n",
       "       'timer_injector_opening'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_control_vars(df):\n",
    "    return df[(df['control_signal'] == True) | (df['input_feature'] == True)].attribute_name.values\n",
    "\n",
    "u4_control_vars = get_control_vars(rds_u4.data_dict[\"train\"].info)\n",
    "u5_control_vars = get_control_vars(rds_u5.data_dict[\"train\"].info)\n",
    "u6_control_vars = get_control_vars(rds_u6.data_dict[\"train\"].info)\n",
    "\n",
    "u5_control_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate dataframes by operating conditions and remove unnecessary columns about operating conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_operating_modes(df):\n",
    "    df_equilibrium_turbine_mode = df[df['equilibrium_turbine_mode'] == True]\n",
    "    df_equilibrium_pump_mode = df[df['equilibrium_pump_mode'] == True]\n",
    "\n",
    "    operating_cond_cols = ['machine_on', 'turbine_mode', 'all',\n",
    "       'equilibrium_turbine_mode', 'dyn_only_on', 'pump_mode',\n",
    "       'equilibrium_pump_mode']\n",
    "    \n",
    "    df_equilibrium_turbine_mode = df_equilibrium_turbine_mode.drop(columns = operating_cond_cols)\n",
    "    df_equilibrium_pump_mode = df_equilibrium_pump_mode.drop(columns = operating_cond_cols)\n",
    "\n",
    "    return df_equilibrium_turbine_mode, df_equilibrium_pump_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train sets\n",
    "u4_train_equil_turbine, u4_train_equil_pump = get_operating_modes(rds_u4.data_dict[\"train\"].measurements)\n",
    "u5_train_equil_turbine, u5_train_equil_pump = get_operating_modes(rds_u5.data_dict[\"train\"].measurements)\n",
    "u6_train_equil_turbine, u6_train_equil_pump = get_operating_modes(rds_u6.data_dict[\"train\"].measurements)\n",
    "\n",
    "# synethetic test sets\n",
    "u5_s01_equil_turbine, u5_s01_equil_pump = get_operating_modes(u5_s01)\n",
    "u5_s02_equil_turbine, u5_s02_equil_pump = get_operating_modes(u5_s02)\n",
    "u6_s01_equil_turbine, u6_s01_equil_pump = get_operating_modes(u6_s01)\n",
    "u6_s02_equil_turbine, u6_s02_equil_pump = get_operating_modes(u6_s02)\n",
    "\n",
    "# real test sets\n",
    "u4_test_equil_turbine, u4_test_equil_pump = get_operating_modes(rds_u4.data_dict[\"test\"].measurements)\n",
    "u5_test_equil_turbine, u5_test_equil_pump = get_operating_modes(rds_u5.data_dict[\"test\"].measurements)\n",
    "u6_test_equil_turbine, u6_test_equil_pump = get_operating_modes(rds_u6.data_dict[\"test\"].measurements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = [u4_train_equil_turbine, u4_train_equil_pump, u5_train_equil_turbine, u5_train_equil_pump, u6_train_equil_turbine, u6_train_equil_pump,\n",
    "            u5_s01_equil_turbine, u5_s01_equil_pump, u5_s02_equil_turbine, u5_s02_equil_pump,\n",
    "            u6_s01_equil_turbine, u6_s01_equil_pump, u6_s02_equil_turbine, u6_s02_equil_pump,\n",
    "            u4_test_equil_turbine, u4_test_equil_pump, u5_test_equil_turbine, u5_test_equil_pump, u6_test_equil_turbine, u6_test_equil_pump]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tot_activepower</th>\n",
       "      <th>plant_tmp</th>\n",
       "      <th>ext_tmp</th>\n",
       "      <th>water_primary_cold_tmp</th>\n",
       "      <th>water_primary_hot_tmp</th>\n",
       "      <th>valve_opening</th>\n",
       "      <th>refri_bath_level</th>\n",
       "      <th>aspi_bath_level</th>\n",
       "      <th>canal_level</th>\n",
       "      <th>canal_tmp</th>\n",
       "      <th>...</th>\n",
       "      <th>stat_magn_02_tmp</th>\n",
       "      <th>stat_coil_ph01_01_tmp</th>\n",
       "      <th>stat_coil_ph01_02_tmp</th>\n",
       "      <th>stat_coil_ph02_01_tmp</th>\n",
       "      <th>stat_coil_ph03_01_tmp</th>\n",
       "      <th>stat_coil_ph03_02_tmp</th>\n",
       "      <th>water_circ_hot_01_tmp</th>\n",
       "      <th>water_circ_hot_02_tmp</th>\n",
       "      <th>water_circ_cold_tmp</th>\n",
       "      <th>machine_off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-16 17:45:30+01:00</th>\n",
       "      <td>-1.198608</td>\n",
       "      <td>-1.394043</td>\n",
       "      <td>-1.691547</td>\n",
       "      <td>-1.754033</td>\n",
       "      <td>-1.809516</td>\n",
       "      <td>1.508591</td>\n",
       "      <td>0.818992</td>\n",
       "      <td>-0.889663</td>\n",
       "      <td>-0.677408</td>\n",
       "      <td>-1.157695</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.574446</td>\n",
       "      <td>-2.630455</td>\n",
       "      <td>-2.56153</td>\n",
       "      <td>-2.524088</td>\n",
       "      <td>-2.704270</td>\n",
       "      <td>-2.640731</td>\n",
       "      <td>-2.416605</td>\n",
       "      <td>-2.271166</td>\n",
       "      <td>-1.348374</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-16 17:46:00+01:00</th>\n",
       "      <td>-1.171863</td>\n",
       "      <td>-1.352097</td>\n",
       "      <td>-1.671501</td>\n",
       "      <td>-1.754033</td>\n",
       "      <td>-1.809516</td>\n",
       "      <td>1.520694</td>\n",
       "      <td>0.914356</td>\n",
       "      <td>-0.833372</td>\n",
       "      <td>-0.700674</td>\n",
       "      <td>-1.157695</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.532496</td>\n",
       "      <td>-2.612666</td>\n",
       "      <td>-2.56153</td>\n",
       "      <td>-2.524088</td>\n",
       "      <td>-2.686109</td>\n",
       "      <td>-2.624558</td>\n",
       "      <td>-2.417479</td>\n",
       "      <td>-2.258681</td>\n",
       "      <td>-1.343124</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-16 17:46:30+01:00</th>\n",
       "      <td>-1.104951</td>\n",
       "      <td>-1.310152</td>\n",
       "      <td>-1.651456</td>\n",
       "      <td>-1.666614</td>\n",
       "      <td>-1.809516</td>\n",
       "      <td>1.520932</td>\n",
       "      <td>1.011599</td>\n",
       "      <td>-0.777081</td>\n",
       "      <td>-0.523275</td>\n",
       "      <td>-1.157695</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.490546</td>\n",
       "      <td>-2.594876</td>\n",
       "      <td>-2.56153</td>\n",
       "      <td>-2.524088</td>\n",
       "      <td>-2.523870</td>\n",
       "      <td>-2.608385</td>\n",
       "      <td>-2.418354</td>\n",
       "      <td>-2.246197</td>\n",
       "      <td>-1.337873</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-16 17:47:00+01:00</th>\n",
       "      <td>-1.005642</td>\n",
       "      <td>-1.268206</td>\n",
       "      <td>-1.631411</td>\n",
       "      <td>-1.643405</td>\n",
       "      <td>-1.809516</td>\n",
       "      <td>1.521169</td>\n",
       "      <td>1.110504</td>\n",
       "      <td>-0.720790</td>\n",
       "      <td>-0.528003</td>\n",
       "      <td>-1.157695</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.448595</td>\n",
       "      <td>-2.577086</td>\n",
       "      <td>-2.56153</td>\n",
       "      <td>-2.524088</td>\n",
       "      <td>-2.523870</td>\n",
       "      <td>-2.592212</td>\n",
       "      <td>-2.408926</td>\n",
       "      <td>-2.233712</td>\n",
       "      <td>-1.332623</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-16 17:47:30+01:00</th>\n",
       "      <td>-0.955382</td>\n",
       "      <td>-1.226260</td>\n",
       "      <td>-1.636706</td>\n",
       "      <td>-1.620197</td>\n",
       "      <td>-1.809516</td>\n",
       "      <td>1.521406</td>\n",
       "      <td>1.194729</td>\n",
       "      <td>-0.664500</td>\n",
       "      <td>-0.555296</td>\n",
       "      <td>-1.157695</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.195495</td>\n",
       "      <td>-2.473511</td>\n",
       "      <td>-2.56153</td>\n",
       "      <td>-2.524088</td>\n",
       "      <td>-2.523870</td>\n",
       "      <td>-2.576040</td>\n",
       "      <td>-2.378894</td>\n",
       "      <td>-2.221228</td>\n",
       "      <td>-1.309009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           tot_activepower  plant_tmp   ext_tmp  \\\n",
       "2020-01-16 17:45:30+01:00        -1.198608  -1.394043 -1.691547   \n",
       "2020-01-16 17:46:00+01:00        -1.171863  -1.352097 -1.671501   \n",
       "2020-01-16 17:46:30+01:00        -1.104951  -1.310152 -1.651456   \n",
       "2020-01-16 17:47:00+01:00        -1.005642  -1.268206 -1.631411   \n",
       "2020-01-16 17:47:30+01:00        -0.955382  -1.226260 -1.636706   \n",
       "\n",
       "                           water_primary_cold_tmp  water_primary_hot_tmp  \\\n",
       "2020-01-16 17:45:30+01:00               -1.754033              -1.809516   \n",
       "2020-01-16 17:46:00+01:00               -1.754033              -1.809516   \n",
       "2020-01-16 17:46:30+01:00               -1.666614              -1.809516   \n",
       "2020-01-16 17:47:00+01:00               -1.643405              -1.809516   \n",
       "2020-01-16 17:47:30+01:00               -1.620197              -1.809516   \n",
       "\n",
       "                           valve_opening  refri_bath_level  aspi_bath_level  \\\n",
       "2020-01-16 17:45:30+01:00       1.508591          0.818992        -0.889663   \n",
       "2020-01-16 17:46:00+01:00       1.520694          0.914356        -0.833372   \n",
       "2020-01-16 17:46:30+01:00       1.520932          1.011599        -0.777081   \n",
       "2020-01-16 17:47:00+01:00       1.521169          1.110504        -0.720790   \n",
       "2020-01-16 17:47:30+01:00       1.521406          1.194729        -0.664500   \n",
       "\n",
       "                           canal_level  canal_tmp  ...  stat_magn_02_tmp  \\\n",
       "2020-01-16 17:45:30+01:00    -0.677408  -1.157695  ...         -4.574446   \n",
       "2020-01-16 17:46:00+01:00    -0.700674  -1.157695  ...         -4.532496   \n",
       "2020-01-16 17:46:30+01:00    -0.523275  -1.157695  ...         -4.490546   \n",
       "2020-01-16 17:47:00+01:00    -0.528003  -1.157695  ...         -4.448595   \n",
       "2020-01-16 17:47:30+01:00    -0.555296  -1.157695  ...         -4.195495   \n",
       "\n",
       "                           stat_coil_ph01_01_tmp  stat_coil_ph01_02_tmp  \\\n",
       "2020-01-16 17:45:30+01:00              -2.630455               -2.56153   \n",
       "2020-01-16 17:46:00+01:00              -2.612666               -2.56153   \n",
       "2020-01-16 17:46:30+01:00              -2.594876               -2.56153   \n",
       "2020-01-16 17:47:00+01:00              -2.577086               -2.56153   \n",
       "2020-01-16 17:47:30+01:00              -2.473511               -2.56153   \n",
       "\n",
       "                           stat_coil_ph02_01_tmp  stat_coil_ph03_01_tmp  \\\n",
       "2020-01-16 17:45:30+01:00              -2.524088              -2.704270   \n",
       "2020-01-16 17:46:00+01:00              -2.524088              -2.686109   \n",
       "2020-01-16 17:46:30+01:00              -2.524088              -2.523870   \n",
       "2020-01-16 17:47:00+01:00              -2.524088              -2.523870   \n",
       "2020-01-16 17:47:30+01:00              -2.524088              -2.523870   \n",
       "\n",
       "                           stat_coil_ph03_02_tmp  water_circ_hot_01_tmp  \\\n",
       "2020-01-16 17:45:30+01:00              -2.640731              -2.416605   \n",
       "2020-01-16 17:46:00+01:00              -2.624558              -2.417479   \n",
       "2020-01-16 17:46:30+01:00              -2.608385              -2.418354   \n",
       "2020-01-16 17:47:00+01:00              -2.592212              -2.408926   \n",
       "2020-01-16 17:47:30+01:00              -2.576040              -2.378894   \n",
       "\n",
       "                           water_circ_hot_02_tmp  water_circ_cold_tmp  \\\n",
       "2020-01-16 17:45:30+01:00              -2.271166            -1.348374   \n",
       "2020-01-16 17:46:00+01:00              -2.258681            -1.343124   \n",
       "2020-01-16 17:46:30+01:00              -2.246197            -1.337873   \n",
       "2020-01-16 17:47:00+01:00              -2.233712            -1.332623   \n",
       "2020-01-16 17:47:30+01:00              -2.221228            -1.309009   \n",
       "\n",
       "                           machine_off  \n",
       "2020-01-16 17:45:30+01:00          0.0  \n",
       "2020-01-16 17:46:00+01:00          0.0  \n",
       "2020-01-16 17:46:30+01:00          0.0  \n",
       "2020-01-16 17:47:00+01:00          0.0  \n",
       "2020-01-16 17:47:30+01:00          0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_dfs = [pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index) for df in list_dfs]\n",
    "\n",
    "# unpack the variables\n",
    "(\n",
    "    u4_train_equil_turbine, u4_train_equil_pump, u5_train_equil_turbine, u5_train_equil_pump, \n",
    "    u6_train_equil_turbine, u6_train_equil_pump, u5_s01_equil_turbine, u5_s01_equil_pump, \n",
    "    u5_s02_equil_turbine, u5_s02_equil_pump, u6_s01_equil_turbine, u6_s01_equil_pump, \n",
    "    u6_s02_equil_turbine, u6_s02_equil_pump, u4_test_equil_turbine, u4_test_equil_pump, \n",
    "    u5_test_equil_turbine, u5_test_equil_pump, u6_test_equil_turbine, u6_test_equil_pump\n",
    ") = scaled_dfs\n",
    "\n",
    "u4_train_equil_turbine.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy this into your notebook to import the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# training data\\nu4_train_equil_turbine = data_preprocessing.u4_train_equil_turbine\\nu4_train_equil_pump = data_preprocessing.u4_train_equil_pump\\nu5_train_equil_turbine = data_preprocessing.u5_train_equil_turbine\\nu5_train_equil_pump = data_preprocessing.u5_train_equil_pump\\nu6_train_equil_turbine = data_preprocessing.u6_train_equil_turbine\\nu6_train_equil_pump = data_preprocessing.u6_train_equil_pump\\n\\n# synethetic test sets\\nu5_s01_equil_turbine = data_preprocessing.u5_s01_equil_turbine\\nu5_s01_equil_pump = data_preprocessing.u5_s01_equil_pump\\nu5_s02_equil_turbine = data_preprocessing.u5_s02_equil_turbine\\nu5_s02_equil_pump = data_preprocessing.u5_s02_equil_pump\\nu6_s01_equil_turbine = data_preprocessing.u6_s01_equil_turbine\\nu6_s01_equil_pump = data_preprocessing.u6_s01_equil_pump\\nu6_s02_equil_turbine = data_preprocessing.u6_s02_equil_turbine\\nu6_s02_equil_pump = data_preprocessing.u6_s02_equil_pump\\n\\n# real test sets\\nu4_test_equil_turbine = data_preprocessing.u4_test_equil_turbine\\nu4_test_equil_pump = data_preprocessing.u4_test_equil_pump\\nu5_test_equil_turbine = data_preprocessing.u5_test_equil_turbine\\nu5_test_equil_pump = data_preprocessing.u5_test_equil_pump\\nu6_test_equil_turbine = data_preprocessing.u6_test_equil_turbine\\nu6_test_equil_pump = data_preprocessing.u6_test_equil_pump\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# training data\n",
    "u4_train_equil_turbine = data_preprocessing.u4_train_equil_turbine\n",
    "u4_train_equil_pump = data_preprocessing.u4_train_equil_pump\n",
    "u5_train_equil_turbine = data_preprocessing.u5_train_equil_turbine\n",
    "u5_train_equil_pump = data_preprocessing.u5_train_equil_pump\n",
    "u6_train_equil_turbine = data_preprocessing.u6_train_equil_turbine\n",
    "u6_train_equil_pump = data_preprocessing.u6_train_equil_pump\n",
    "\n",
    "# synethetic test sets\n",
    "u5_s01_equil_turbine = data_preprocessing.u5_s01_equil_turbine\n",
    "u5_s01_equil_pump = data_preprocessing.u5_s01_equil_pump\n",
    "u5_s02_equil_turbine = data_preprocessing.u5_s02_equil_turbine\n",
    "u5_s02_equil_pump = data_preprocessing.u5_s02_equil_pump\n",
    "u6_s01_equil_turbine = data_preprocessing.u6_s01_equil_turbine\n",
    "u6_s01_equil_pump = data_preprocessing.u6_s01_equil_pump\n",
    "u6_s02_equil_turbine = data_preprocessing.u6_s02_equil_turbine\n",
    "u6_s02_equil_pump = data_preprocessing.u6_s02_equil_pump\n",
    "\n",
    "# real test sets\n",
    "u4_test_equil_turbine = data_preprocessing.u4_test_equil_turbine\n",
    "u4_test_equil_pump = data_preprocessing.u4_test_equil_pump\n",
    "u5_test_equil_turbine = data_preprocessing.u5_test_equil_turbine\n",
    "u5_test_equil_pump = data_preprocessing.u5_test_equil_pump\n",
    "u6_test_equil_turbine = data_preprocessing.u6_test_equil_turbine\n",
    "u6_test_equil_pump = data_preprocessing.u6_test_equil_pump\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples:\n",
    "\n",
    "For Unit 4:\n",
    "- train on u4_train_equil_pump, test on u4_test_equil_pump\n",
    "\n",
    "For Unit 5:\n",
    "- train on u5_train_equil_turbine, test on u5_s01_equil_turbine, u5_s02_equil_turbine, u5_test_equil_turbine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "civil-426",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
