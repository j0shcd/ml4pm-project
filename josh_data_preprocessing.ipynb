{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pyarrow.parquet as pq\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# hv.renderer('bokeh').theme = 'dark_minimal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_root = Path(r\"C:\\Users\\Turquin\\Documents\\MLFPMA - Machine Learning for Predictive Maintenance Application\\Project\\Dataset\") # Raw string works without escaping \\\n",
    "dataset_root = Path(\"./Dataset\")\n",
    "\n",
    "@dataclass\n",
    "class Case():\n",
    "    info: pd.DataFrame\n",
    "    measurements: pd.DataFrame\n",
    "\n",
    "\n",
    "class RawDataset():\n",
    "    def __init__(self, root, unit = \"VG4\", load_training=False, load_synthetic=False, load_anomalies=False) -> None:\n",
    "        read_pq_file = lambda f: pq.read_table(root / f).to_pandas()\n",
    "        \n",
    "        cases = {\n",
    "            \"test\": [f\"{unit}_generator_data_testing_real_measurements.parquet\", root / f\"{unit}_generator_data_testing_real_info.csv\" ], \n",
    "        }\n",
    "\n",
    "        if load_training:\n",
    "            cases = {\n",
    "                **cases,\n",
    "                \"train\": [f\"{unit}_generator_data_training_measurements.parquet\", root / f\"{unit}_generator_data_training_info.csv\" ], \n",
    "            }\n",
    "\n",
    "        if load_synthetic:\n",
    "            cases = {\n",
    "                **cases,\n",
    "                \"test_s01\": [f\"{unit}_generator_data_testing_synthetic_01_measurements.parquet\", root / f\"{unit}_generator_data_testing_synthetic_01_info.csv\"], \n",
    "                \"test_s02\": [f\"{unit}_generator_data_testing_synthetic_02_measurements.parquet\", root / f\"{unit}_generator_data_testing_synthetic_02_info.csv\"]\n",
    "            }\n",
    "\n",
    "        if load_anomalies:\n",
    "            anomaly_folder = Path(\"synthetic_anomalies\")  # Relative path\n",
    "            subdataset = [\"01\", \"02\"]\n",
    "            anomaly_types = [\"a\", \"b\", \"c\"]\n",
    "            for anomaly in subdataset:\n",
    "                for subtype in anomaly_types:\n",
    "                    anomaly_key = f\"anomaly_{anomaly}_type_{subtype}\"\n",
    "                    anomaly_file = f\"{unit}_anomaly_{anomaly}_type_{subtype}.parquet\"\n",
    "                    full_anomaly_path = root / anomaly_folder / anomaly_file\n",
    "                    if full_anomaly_path.exists():\n",
    "                        cases[anomaly_key] = [anomaly_folder / anomaly_file, None]\n",
    "\n",
    "        \n",
    "        self.data_dict = dict()\n",
    "        \n",
    "        for id_c, c in cases.items():\n",
    "            # if you need to verify the parquet header:\n",
    "            # pq_rows = RawDataset.read_parquet_schema_df(root / c[0])\n",
    "            measurements = read_pq_file(c[0])\n",
    "            info = pd.read_csv(c[1]) if c[1] is not None else None\n",
    "            self.data_dict[id_c] = Case(info, measurements)\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_parquet_schema_df(uri: str) -> pd.DataFrame:\n",
    "        \"\"\"Return a Pandas dataframe corresponding to the schema of a local URI of a parquet file.\n",
    "\n",
    "        The returned dataframe has the columns: column, pa_dtype\n",
    "        \"\"\"\n",
    "        # Ref: https://stackoverflow.com/a/64288036/\n",
    "        schema = pq.read_schema(uri, memory_map=True)\n",
    "        schema = pd.DataFrame(({\"column\": name, \"pa_dtype\": str(pa_dtype)} for name, pa_dtype in zip(schema.names, schema.types)))\n",
    "        schema = schema.reindex(columns=[\"column\", \"pa_dtype\"], fill_value=pd.NA)  # Ensures columns in case the parquet file has an empty dataframe.\n",
    "        return schema\n",
    "    \n",
    "\n",
    "rds_u4 = RawDataset(dataset_root, \"VG4\", load_synthetic=False, load_training=True)\n",
    "rds_u5 = RawDataset(dataset_root, \"VG5\", load_synthetic=True, load_training=True, load_anomalies=True)\n",
    "rds_u6 = RawDataset(dataset_root, \"VG6\", load_synthetic=True, load_training=True, load_anomalies=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_anomaly_ground_truth(rds):\n",
    "    subdataset = [\"01\", \"02\"]\n",
    "    anomaly_types = [\"a\", \"b\", \"c\"]\n",
    "\n",
    "    results = []\n",
    "    for anomaly in subdataset:\n",
    "        test_s012 = rds.data_dict[f'test_s{anomaly}'].measurements\n",
    "\n",
    "        for subtype in anomaly_types:\n",
    "            anomaly_key = f\"anomaly_{anomaly}_type_{subtype}\"\n",
    "            labeled_df = rds.data_dict[anomaly_key].measurements\n",
    "            test_s012.loc[labeled_df['ground_truth'] == 1, anomaly_key] = 1\n",
    "        \n",
    "        test_s012['anomaly'] = (test_s012[[f'anomaly_{anomaly}_type_a',f'anomaly_{anomaly}_type_b',f'anomaly_{anomaly}_type_c']].max(axis=1) == 1).astype(int)\n",
    "        results.append(test_s012)\n",
    "\n",
    "    return results\n",
    "\n",
    "u5_s01, u5_s02 = add_anomaly_ground_truth(rds_u5)\n",
    "u6_s01, u6_s02 = add_anomaly_ground_truth(rds_u6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tot_activepower', 'charge', 'coupler_position',\n",
       "       'injector_01_opening', 'injector_02_opening',\n",
       "       'injector_03_opening', 'injector_04_opening',\n",
       "       'injector_05_opening', 'pump_calculated_flow',\n",
       "       'pump_pressure_diff', 'pump_rotspeed', 'turbine_pressure',\n",
       "       'turbine_rotspeed', 'water_primary_pump_01_opening',\n",
       "       'water_primary_pump_02_opening', 'timer_turbine_on_off',\n",
       "       'timer_injector_opening'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_control_vars(df):\n",
    "    return df[(df['control_signal'] == True) | (df['input_feature'] == True)].attribute_name.values\n",
    "\n",
    "u4_control_vars = get_control_vars(rds_u4.data_dict[\"train\"].info)\n",
    "u5_control_vars = get_control_vars(rds_u5.data_dict[\"train\"].info)\n",
    "u6_control_vars = get_control_vars(rds_u6.data_dict[\"train\"].info)\n",
    "\n",
    "u5_control_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate dataframes by operating conditions and remove unnecessary columns about operating conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_operating_modes(df):\n",
    "    df_equilibrium_turbine_mode = df[df['equilibrium_turbine_mode'] == True]\n",
    "    df_equilibrium_pump_mode = df[df['equilibrium_pump_mode'] == True]\n",
    "\n",
    "    operating_cond_cols = ['machine_on', 'turbine_mode', 'all',\n",
    "       'equilibrium_turbine_mode', 'dyn_only_on', 'pump_mode',\n",
    "       'equilibrium_pump_mode']\n",
    "    \n",
    "    df_equilibrium_turbine_mode = df_equilibrium_turbine_mode.drop(columns = operating_cond_cols)\n",
    "    df_equilibrium_pump_mode = df_equilibrium_pump_mode.drop(columns = operating_cond_cols)\n",
    "\n",
    "    return df_equilibrium_turbine_mode, df_equilibrium_pump_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train sets\n",
    "u4_train_equil_turbine, u4_train_equil_pump = get_operating_modes(rds_u4.data_dict[\"train\"].measurements)\n",
    "u5_train_equil_turbine, u5_train_equil_pump = get_operating_modes(rds_u5.data_dict[\"train\"].measurements)\n",
    "u6_train_equil_turbine, u6_train_equil_pump = get_operating_modes(rds_u6.data_dict[\"train\"].measurements)\n",
    "\n",
    "# synethetic test sets\n",
    "u5_s01_equil_turbine, u5_s01_equil_pump = get_operating_modes(u5_s01)\n",
    "u5_s02_equil_turbine, u5_s02_equil_pump = get_operating_modes(u5_s02)\n",
    "u6_s01_equil_turbine, u6_s01_equil_pump = get_operating_modes(u6_s01)\n",
    "u6_s02_equil_turbine, u6_s02_equil_pump = get_operating_modes(u6_s02)\n",
    "\n",
    "# real test sets\n",
    "u4_test_equil_turbine, u4_test_equil_pump = get_operating_modes(rds_u4.data_dict[\"test\"].measurements)\n",
    "u5_test_equil_turbine, u5_test_equil_pump = get_operating_modes(rds_u5.data_dict[\"test\"].measurements)\n",
    "u6_test_equil_turbine, u6_test_equil_pump = get_operating_modes(rds_u6.data_dict[\"test\"].measurements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = [u4_train_equil_turbine, u4_train_equil_pump, u5_train_equil_turbine, u5_train_equil_pump, u6_train_equil_turbine, u6_train_equil_pump,\n",
    "            u5_s01_equil_turbine, u5_s01_equil_pump, u5_s02_equil_turbine, u5_s02_equil_pump,\n",
    "            u6_s01_equil_turbine, u6_s01_equil_pump, u6_s02_equil_turbine, u6_s02_equil_pump,\n",
    "            u4_test_equil_turbine, u4_test_equil_pump, u5_test_equil_turbine, u5_test_equil_pump, u6_test_equil_turbine, u6_test_equil_pump]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaled_dfs = [pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index) for df in list_dfs]\n",
    "\n",
    "# # unpack the variables\n",
    "# (\n",
    "#     u4_train_equil_turbine, u4_train_equil_pump, u5_train_equil_turbine, u5_train_equil_pump, \n",
    "#     u6_train_equil_turbine, u6_train_equil_pump, u5_s01_equil_turbine, u5_s01_equil_pump, \n",
    "#     u5_s02_equil_turbine, u5_s02_equil_pump, u6_s01_equil_turbine, u6_s01_equil_pump, \n",
    "#     u6_s02_equil_turbine, u6_s02_equil_pump, u4_test_equil_turbine, u4_test_equil_pump, \n",
    "#     u5_test_equil_turbine, u5_test_equil_pump, u6_test_equil_turbine, u6_test_equil_pump\n",
    "# ) = scaled_dfs\n",
    "\n",
    "# u4_train_equil_turbine.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    df['minute'] = df.index.minute\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day'] = df.index.day\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['is_weekend'] = df.index.dayofweek.isin([5, 6]).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = [add_time_features(df) for df in list_dfs]\n",
    "# print(list_dfs[0].columns)  # Check the first DataFrame in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ema_features(df, span=10, vars=None):\n",
    "    \"\"\"\n",
    "    Adds EMA features to the DataFrame for each specified column that exists in the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    df (DataFrame): The input DataFrame containing the control variables.\n",
    "    span (int): The number of periods over which to calculate the EMA.\n",
    "    vars (list): List of variables to compute the EMA for. If None, apply EMA to all columns.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: The original DataFrame with added EMA columns for the existing specified variables.\n",
    "    \"\"\"\n",
    "    ema_df = df.copy()\n",
    "    existing_vars = [col for col in vars if col in df.columns]\n",
    "    for col in existing_vars:\n",
    "        ema_df[f'{col}_ema_{span}'] = df[col].ewm(span=span, adjust=False).mean()\n",
    "    return ema_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "u5_train_equil_pump = add_ema_features(u5_train_equil_pump, span=10, vars=u5_control_vars)\n",
    "u5_s01_equil_pump = add_ema_features(u5_s01_equil_pump, span=10, vars=u5_control_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tot_activepower', 'ext_tmp', 'plant_tmp', 'charge', 'coupler_position',\n",
       "       'injector_01_opening', 'injector_02_opening', 'injector_03_opening',\n",
       "       'injector_04_opening', 'injector_05_opening',\n",
       "       ...\n",
       "       'injector_03_opening_ema_10', 'injector_04_opening_ema_10',\n",
       "       'injector_05_opening_ema_10', 'pump_calculated_flow_ema_10',\n",
       "       'pump_pressure_diff_ema_10', 'pump_rotspeed_ema_10',\n",
       "       'turbine_pressure_ema_10', 'turbine_rotspeed_ema_10',\n",
       "       'water_primary_pump_01_opening_ema_10',\n",
       "       'water_primary_pump_02_opening_ema_10'],\n",
       "      dtype='object', length=119)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u5_s01_equil_pump.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22199 rows Ã— 119 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy this into your notebook to import the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# training data\\nu4_train_equil_turbine = data_preprocessing.u4_train_equil_turbine\\nu4_train_equil_pump = data_preprocessing.u4_train_equil_pump\\nu5_train_equil_turbine = data_preprocessing.u5_train_equil_turbine\\nu5_train_equil_pump = data_preprocessing.u5_train_equil_pump\\nu6_train_equil_turbine = data_preprocessing.u6_train_equil_turbine\\nu6_train_equil_pump = data_preprocessing.u6_train_equil_pump\\n\\n# synethetic test sets\\nu5_s01_equil_turbine = data_preprocessing.u5_s01_equil_turbine\\nu5_s01_equil_pump = data_preprocessing.u5_s01_equil_pump\\nu5_s02_equil_turbine = data_preprocessing.u5_s02_equil_turbine\\nu5_s02_equil_pump = data_preprocessing.u5_s02_equil_pump\\nu6_s01_equil_turbine = data_preprocessing.u6_s01_equil_turbine\\nu6_s01_equil_pump = data_preprocessing.u6_s01_equil_pump\\nu6_s02_equil_turbine = data_preprocessing.u6_s02_equil_turbine\\nu6_s02_equil_pump = data_preprocessing.u6_s02_equil_pump\\n\\n# real test sets\\nu4_test_equil_turbine = data_preprocessing.u4_test_equil_turbine\\nu4_test_equil_pump = data_preprocessing.u4_test_equil_pump\\nu5_test_equil_turbine = data_preprocessing.u5_test_equil_turbine\\nu5_test_equil_pump = data_preprocessing.u5_test_equil_pump\\nu6_test_equil_turbine = data_preprocessing.u6_test_equil_turbine\\nu6_test_equil_pump = data_preprocessing.u6_test_equil_pump\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# training data\n",
    "u4_train_equil_turbine = data_preprocessing.u4_train_equil_turbine\n",
    "u4_train_equil_pump = data_preprocessing.u4_train_equil_pump\n",
    "u5_train_equil_turbine = data_preprocessing.u5_train_equil_turbine\n",
    "u5_train_equil_pump = data_preprocessing.u5_train_equil_pump\n",
    "u6_train_equil_turbine = data_preprocessing.u6_train_equil_turbine\n",
    "u6_train_equil_pump = data_preprocessing.u6_train_equil_pump\n",
    "\n",
    "# synethetic test sets\n",
    "u5_s01_equil_turbine = data_preprocessing.u5_s01_equil_turbine\n",
    "u5_s01_equil_pump = data_preprocessing.u5_s01_equil_pump\n",
    "u5_s02_equil_turbine = data_preprocessing.u5_s02_equil_turbine\n",
    "u5_s02_equil_pump = data_preprocessing.u5_s02_equil_pump\n",
    "u6_s01_equil_turbine = data_preprocessing.u6_s01_equil_turbine\n",
    "u6_s01_equil_pump = data_preprocessing.u6_s01_equil_pump\n",
    "u6_s02_equil_turbine = data_preprocessing.u6_s02_equil_turbine\n",
    "u6_s02_equil_pump = data_preprocessing.u6_s02_equil_pump\n",
    "\n",
    "# real test sets\n",
    "u4_test_equil_turbine = data_preprocessing.u4_test_equil_turbine\n",
    "u4_test_equil_pump = data_preprocessing.u4_test_equil_pump\n",
    "u5_test_equil_turbine = data_preprocessing.u5_test_equil_turbine\n",
    "u5_test_equil_pump = data_preprocessing.u5_test_equil_pump\n",
    "u6_test_equil_turbine = data_preprocessing.u6_test_equil_turbine\n",
    "u6_test_equil_pump = data_preprocessing.u6_test_equil_pump\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples:\n",
    "\n",
    "For Unit 4:\n",
    "- train on u4_train_equil_pump, test on u4_test_equil_pump\n",
    "\n",
    "For Unit 5:\n",
    "- train on u5_train_equil_turbine, test on u5_s01_equil_turbine, u5_s02_equil_turbine, u5_test_equil_turbine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4pm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
